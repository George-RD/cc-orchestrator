# Agent-Specific Metrics Configuration

## Core Metrics

### Response Time Metrics
```yaml
response_time:
  type: histogram
  unit: milliseconds
  buckets: [10, 50, 100, 250, 500, 1000, 2500, 5000, 10000]
  labels:
    - agent
    - task_type
    - complexity
  aggregations:
    - p50
    - p75
    - p90
    - p95
    - p99
```

### Task Completion Metrics
```yaml
task_completion:
  type: counter
  labels:
    - agent
    - task_type
    - status (success|failure|timeout|cancelled)
    - complexity
  derived_metrics:
    - success_rate: success / (success + failure)
    - completion_rate: (success + failure) / total
```

### Error Rate Metrics
```yaml
error_rate:
  type: counter
  labels:
    - agent
    - error_type
    - severity
    - recoverable (true|false)
  alerts:
    - threshold: rate > 0.05
      severity: warning
    - threshold: rate > 0.10
      severity: critical
```

### Confidence Score Distribution
```yaml
confidence_scores:
  type: histogram
  unit: ratio (0.0-1.0)
  buckets: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1.0]
  labels:
    - agent
    - decision_type
  thresholds:
    - autonomous: >= 0.95
    - supervised: >= 0.75
    - manual: < 0.75
```

## Agent-Specific Metrics

### Orchestrator Metrics
```yaml
orchestrator:
  delegation_count:
    type: counter
    labels:
      - target_agent
      - task_type
  
  coordination_overhead:
    type: histogram
    description: Time spent coordinating vs executing
    unit: milliseconds
  
  parallel_execution:
    type: gauge
    description: Number of parallel tasks being coordinated
    
  decision_accuracy:
    type: counter
    description: Correct vs incorrect routing decisions
    labels:
      - decision_type
      - outcome
```

### Backend Agent Metrics
```yaml
backend:
  api_endpoints_created:
    type: counter
    labels:
      - method
      - resource
  
  database_operations:
    type: counter
    labels:
      - operation (select|insert|update|delete)
      - table
  
  code_complexity:
    type: histogram
    description: Cyclomatic complexity of generated code
    buckets: [1, 5, 10, 15, 20, 30, 50]
  
  security_violations_detected:
    type: counter
    labels:
      - violation_type
      - severity
```

### Frontend Agent Metrics
```yaml
frontend:
  components_created:
    type: counter
    labels:
      - component_type
      - framework
  
  accessibility_score:
    type: gauge
    description: WCAG compliance score (0-100)
    
  bundle_size:
    type: histogram
    unit: kilobytes
    buckets: [10, 50, 100, 250, 500, 1000]
    
  lighthouse_scores:
    type: gauge
    labels:
      - metric (performance|accessibility|seo|best_practices)
```

### QA Agent Metrics
```yaml
qa:
  tests_written:
    type: counter
    labels:
      - test_type (unit|integration|e2e)
      - framework
  
  bugs_detected:
    type: counter
    labels:
      - severity
      - category
  
  code_coverage:
    type: gauge
    description: Percentage of code covered by tests
    labels:
      - coverage_type (line|branch|function)
  
  false_positive_rate:
    type: gauge
    description: Ratio of false positives to total issues raised
```

### Documentation Agent Metrics
```yaml
docs:
  pages_created:
    type: counter
    labels:
      - doc_type (api|user_guide|tutorial|reference)
  
  documentation_completeness:
    type: gauge
    description: Percentage of code with documentation
    
  readability_score:
    type: histogram
    description: Flesch reading ease score
    buckets: [30, 40, 50, 60, 70, 80, 90]
    
  stale_documentation:
    type: gauge
    description: Number of docs not updated after code changes
```

## Business Metrics

### Development Velocity
```yaml
velocity:
  stories_completed:
    type: counter
    labels:
      - story_points
      - sprint
  
  cycle_time:
    type: histogram
    description: Time from task start to completion
    unit: hours
    buckets: [1, 4, 8, 24, 48, 72, 168]
  
  lead_time:
    type: histogram
    description: Time from request to deployment
    unit: hours
    buckets: [1, 4, 8, 24, 48, 72, 168, 336]
```

### Quality Metrics
```yaml
quality:
  defect_escape_rate:
    type: gauge
    description: Bugs found in production vs development
    
  mean_time_to_recovery:
    type: histogram
    description: Time to fix production issues
    unit: minutes
    buckets: [5, 15, 30, 60, 120, 240, 480]
    
  code_review_coverage:
    type: gauge
    description: Percentage of code that went through review
    
  technical_debt_ratio:
    type: gauge
    description: Ratio of remediation cost to development cost
```

### Cost Efficiency
```yaml
efficiency:
  token_usage:
    type: counter
    labels:
      - model (sonnet-4|opus-4)
      - operation_type
    cost_calculation: tokens * price_per_token
  
  compute_time:
    type: counter
    unit: seconds
    labels:
      - agent
      - task_type
  
  rework_ratio:
    type: gauge
    description: Percentage of tasks requiring rework
```

## Alerting Rules

### Performance Alerts
```yaml
alerts:
  - name: high_response_time
    condition: response_time_p95 > 5000
    duration: 5m
    severity: warning
    
  - name: agent_unavailable
    condition: up == 0
    duration: 1m
    severity: critical
    
  - name: high_error_rate
    condition: error_rate > 0.10
    duration: 5m
    severity: critical
```

### Capacity Alerts
```yaml
capacity_alerts:
  - name: high_queue_depth
    condition: task_queue_depth > 100
    duration: 10m
    severity: warning
    
  - name: agent_overload
    condition: cpu_usage > 0.80 OR memory_usage > 0.80
    duration: 5m
    severity: warning
```

### Business Alerts
```yaml
business_alerts:
  - name: velocity_drop
    condition: stories_completed < historical_avg * 0.7
    duration: 1d
    severity: warning
    
  - name: quality_degradation  
    condition: defect_escape_rate > 0.05
    duration: 1h
    severity: critical
```

## Dashboards Configuration

### Agent Performance Dashboard
```yaml
agent_performance:
  panels:
    - title: "Task Completion Rate"
      query: "rate(task_completion[5m])"
      visualization: line_chart
      
    - title: "Response Time Distribution"
      query: "histogram_quantile(0.95, response_time)"
      visualization: heatmap
      
    - title: "Agent Utilization"
      query: "avg(agent_busy_time / agent_total_time)"
      visualization: gauge
      
    - title: "Error Rate by Agent"
      query: "rate(errors[5m]) by (agent)"
      visualization: bar_chart
```

### Development Metrics Dashboard
```yaml
development_metrics:
  panels:
    - title: "Sprint Velocity"
      query: "sum(stories_completed) by (sprint)"
      visualization: bar_chart
      
    - title: "Cycle Time Trend"
      query: "histogram_quantile(0.5, cycle_time)"
      visualization: line_chart
      
    - title: "Code Coverage"
      query: "avg(code_coverage) by (project)"
      visualization: gauge
      
    - title: "PR Merge Time"
      query: "histogram_quantile(0.9, pr_merge_time)"
      visualization: line_chart
```

## Metric Collection Implementation

### Instrumentation Example
```javascript
// Metric collection wrapper
const withMetrics = (metricName, labels, fn) => {
  const startTime = Date.now();
  
  try {
    const result = await fn();
    
    metrics.counter(`${metricName}_total`, labels).inc();
    metrics.histogram(`${metricName}_duration`, labels)
      .observe(Date.now() - startTime);
    
    return result;
  } catch (error) {
    metrics.counter(`${metricName}_errors`, {
      ...labels,
      error_type: error.constructor.name
    }).inc();
    
    throw error;
  }
};

// Usage
const result = await withMetrics(
  'task_execution',
  { agent: 'backend', task_type: 'api_creation' },
  async () => await createAPI(spec)
);
```

### Batch Metric Updates
```javascript
// Efficient metric batching
class MetricBatcher {
  constructor(flushInterval = 10000) {
    this.batch = new Map();
    setInterval(() => this.flush(), flushInterval);
  }
  
  record(metric, value, labels = {}) {
    const key = `${metric}:${JSON.stringify(labels)}`;
    if (!this.batch.has(key)) {
      this.batch.set(key, []);
    }
    this.batch.get(key).push(value);
  }
  
  flush() {
    for (const [key, values] of this.batch) {
      const [metric, labelsStr] = key.split(':');
      const labels = JSON.parse(labelsStr);
      
      // Send aggregated metrics
      metrics.histogram(metric, labels).observe(values);
    }
    
    this.batch.clear();
  }
}
```
